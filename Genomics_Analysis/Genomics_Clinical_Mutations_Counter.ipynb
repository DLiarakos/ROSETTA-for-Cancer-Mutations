{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65d28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6e8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd0=os.getcwd()\n",
    "cwd_interim=os.path.join(cwd0,'interim_files/')\n",
    "cwd_refdata=os.path.join(cwd0,'reference_data_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7245426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Useful Functions \n",
    "setlen=lambda x:len(set(x)) # Calculate length of set of a list."
   ]
  },
  {
   "cell_type": "raw",
   "id": "321ef8cb",
   "metadata": {},
   "source": [
    "# Uncomment the following lines if updating raw dataset,otherwise the code begins at block marked,\n",
    "\"==BEGIN HERE==\" ."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa97ed0a",
   "metadata": {},
   "source": [
    "# Find Studies\n",
    "# cwd='C:/Users/GM/Downloads/Genomics_Analysis_FREEZE4_GM_Apr2021/cbioportal_raw_EXOME142_Mar2021'\n",
    "cwd=os.path.join(cwd0,'cbioportal_raw_EXOME139') # fresh cbioportal download directory\n",
    "list_study_dirs=['acbc_mskcc_2015','acc_tcga_pan_can_atlas_2018','acyc_mda_2015','acyc_mskcc_2013','acyc_sanger_2013','all_stjude_2013','all_stjude_2015','all_stjude_2016','aml_target_2018_pub','angs_project_painter_2018','bfn_duke_nus_2015','blca_bgi','blca_cornell_2016','blca_dfarber_mskcc_2014','blca_tcga_pub_2017','brca_bccrc','brca_broad','brca_igr_2015','brca_mbcproject_wagle_2017','brca_sanger','brca_tcga_pan_can_atlas_2018','ccrcc_irc_2014','ccrcc_utokyo_2013','cesc_tcga_pan_can_atlas_2018','chol_jhu_2013','chol_nccs_2013','chol_tcga_pan_can_atlas_2018','cll_iuopa_2015','cllsll_icgc_2011','coadread_dfci_2016','coadread_genentech','coadread_tcga_pan_can_atlas_2018','ctcl_columbia_2015','desm_broad_2015','dlbc_broad_2012','dlbc_tcga_pan_can_atlas_2018','dlbcl_dfci_2018','dlbcl_duke_2017','egc_tmucih_2015','es_dfarber_broad_2014','es_iocurie_2014','esca_tcga_pan_can_atlas_2018','escc_icgc','escc_ucla_2014','gbc_shanghai_2014','gbm_tcga_pan_can_atlas_2018','hcc_inserm_fr_2015','hnsc_broad','hnsc_jhu','hnsc_mdanderson_2013','hnsc_tcga_pan_can_atlas_2018','kich_tcga_pan_can_atlas_2018','kirc_bgi','kirc_tcga_pan_can_atlas_2018','kirp_tcga_pan_can_atlas_2018','laml_tcga_pan_can_atlas_2018','lcll_broad_2013','lgg_ucsf_2014','lgggbm_tcga_pub','lihc_amc_prv','lihc_riken','lihc_tcga_pan_can_atlas_2018','luad_broad','luad_mskcc_2015','luad_tcga_pan_can_atlas_2018','lusc_tcga_pan_can_atlas_2018','mbl_broad_2012','mbl_icgc','mbl_pcgp','mbl_sickkids_2016','mcl_idibips_2013','mds_tokyo_2011','mel_tsam_liang_2017','meso_tcga_pan_can_atlas_2018','mm_broad','mpnst_mskcc','mrt_bcgsc_2016','nbl_amc_2012','nbl_broad_2013','nbl_target_2018_pub','nbl_ucologne_2015','nccrcc_genentech_2014','nepc_wcm_2016','nhl_bcgsc_2011','nhl_bcgsc_2013','npc_nusingapore','nsclc_tcga_broad_2016','ov_tcga_pan_can_atlas_2018','paac_jhu_2014','paad_icgc','paad_qcmg_uq_2016','paad_tcga_pan_can_atlas_2018','paad_utsw_2015','panet_arcnet_2017','panet_jhu_2011','panet_shanghai_2013','past_dkfz_heidelberg_2013','pcnsl_mayo_2015','pcpg_tcga_pan_can_atlas_2018','plmeso_nyu_2015','prad_broad','prad_broad_2013','prad_cpcg_2017','prad_eururol_2017','prad_fhcrc','prad_mich','prad_p1000','prad_su2c_2015','prad_tcga_pan_can_atlas_2018','rms_nih_2014','rt_target_2018_pub','sarc_tcga_pan_can_atlas_2018','sclc_cancercell_gardner_2017','sclc_clcgp','sclc_jhu','sclc_ucologne_2015','skcm_broad','skcm_broad_brafresist_2012','skcm_broad_dfarber','skcm_tcga_pan_can_atlas_2018','skcm_ucla_2016','skcm_yale','stad_pfizer_uhongkong','stad_tcga_pan_can_atlas_2018','stad_uhongkong','stad_utokyo','stes_tcga_pub','tet_nci_2014','tgct_tcga_pan_can_atlas_2018','thca_tcga_pan_can_atlas_2018','thym_tcga_pan_can_atlas_2018','uccc_nih_2017','ucec_tcga_pan_can_atlas_2018','ucs_jhu_2014','ucs_tcga_pan_can_atlas_2018','um_qimr_2016','uvm_tcga_pan_can_atlas_2018','vsc_cuk_2018','wt_target_2018_pub']\n",
    "print('Number of Studies included:',len(list_study_dirs),'\\n The following studies are not present in cbioportal_raw_EXOME139/ folder. Please download by running script provided in the folder: ',[istudy for istudy in list_study_dirs if not os.path.isdir(os.path.join(cwd,istudy))]) # Second value should be null vector to ensure all studies are downloaded and unzipped in current directory."
   ]
  },
  {
   "cell_type": "raw",
   "id": "68c0ef07",
   "metadata": {},
   "source": [
    "### Part 1: Curated Clinical Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0000ebc1",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Import Clinical Data\n",
    "# when clinical folder defined in cwd0 directory\n",
    "cldirlist0=[os.path.join(cwd0,'clinical',idir) for idir in os.listdir(os.path.join(cwd0,\"clinical\")) if os.path.isdir(os.path.join(cwd0,'clinical',idir))]\n",
    "cldirlist1=[os.path.join(idir,idir1) for idir in cldirlist0 for idir1 in os.listdir(idir)]\n",
    "\n",
    "# limit to included studies\n",
    "clinical_file_list=[os.path.join(idir,'data_clinical_sample_v2.txt') for idir in cldirlist1 if any([row in idir for row in list_study_dirs])] \n",
    "\n",
    "N_LongiSamples={}\n",
    "list_df_clinical=[]\n",
    "for istudypath in clinical_file_list:\n",
    "    Study_ID=istudypath.split('\\\\')[-2]\n",
    "    df_clinical_istudy=pd.read_csv(istudypath,sep='\\t',comment='#',dtype=str)\n",
    "    # Remove longitudinal samples\n",
    "    N_LongiSamples[Study_ID]=(len(df_clinical_istudy.PATIENT_ID)-setlen(df_clinical_istudy.PATIENT_ID)) # Record how many longitudinal samples are removed within every study\n",
    "    df_clinical_istudy=df_clinical_istudy.drop_duplicates(subset='PATIENT_ID',keep='first')\n",
    "    df_clinical_istudy['STUDY_ID']=Study_ID\n",
    "    keepcols=['STUDY_ID','PATIENT_ID','SAMPLE_ID','CODE'] # These columns are ALWAYS present in the curated clinical file.\n",
    "    list_df_clinical=list_df_clinical+[df_clinical_istudy[keepcols]]\n",
    "    del df_clinical_istudy\n",
    "df_clinical=pd.concat(list_df_clinical).reset_index(drop=True) # A unified clinical matrix with ALL the clinical data.\n",
    "print('Total Number of Studies:',len(list_study_dirs),'\\nClinical Data Avaliable for Samples(=Patients or cases)):',len(df_clinical),'\\nNumber of Longitudinal Samples Dropped: ',sum(N_LongiSamples.values()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e035a7f3",
   "metadata": {},
   "source": [
    "# Note list of histological codes\n",
    "histcodes=list(set(df_clinical.CODE.sort_values()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "057d9d72",
   "metadata": {},
   "source": [
    "# Import cbioportal studies and sort reverse chronologically\n",
    "df_cbiostudies=pd.read_excel(os.path.join(cwd_refdata,'Table2_v6.xlsx'),dtype=str)\n",
    "df_cbiostudies['Year']=df_cbiostudies['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "042e1356",
   "metadata": {},
   "source": [
    "df_clinical['Year']=[df_cbiostudies.Year[df_cbiostudies.Study_ID==stid].values[0] for stid in df_clinical.STUDY_ID.values]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07ef5981",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Filter repeated samples acrross studies within a given histological code. Note that this filter assumes that dataframes preseve indices upon copying and slicing. If that functinality changes, the codes need to change.\n",
    "list_redunPID=[]\n",
    "df_clinical_NR=df_clinical[:].copy() # initialize non redundant clinical samples\n",
    "for icode in histcodes:\n",
    "    # Find all patient IDs within a given hist code\n",
    "    df_patient=df_clinical[df_clinical.CODE==icode]\n",
    "    # Find repeating patient IDs\n",
    "    for pid in set(df_patient.PATIENT_ID.values):\n",
    "        if sum(df_patient.PATIENT_ID==pid)>1:\n",
    "            df_tmp_remove=df_patient[df_patient.PATIENT_ID==pid].sort_values('Year',ascending=False)\n",
    "            for idx_drop in df_tmp_remove.index[1:]:\n",
    "                df_clinical_NR.drop(idx_drop,inplace=True)\n",
    "            del df_tmp_remove\n",
    "    df_patient=df_patient[[sum(df_patient.PATIENT_ID==pid)>1 for pid in df_patient.PATIENT_ID.values]].sort_values('SAMPLE_ID')\n",
    "    list_redunPID=list_redunPID+[df_patient]    \n",
    "    del df_patient"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04038da3",
   "metadata": {},
   "source": [
    "print('Clinical Data Processed. Number of Redundant Samples:',sum([len(dfi) for dfi in list_redunPID]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b5c4b60",
   "metadata": {},
   "source": [
    "df_redundants=pd.concat(list_redunPID).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "142b82af",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "print('Set of ROSETTA codes with redundant samples and corresponding studies:\\n',[[icode]+list(set(df_redundants.STUDY_ID[df_redundants.CODE==icode])) for icode in histcodes if len(set(df_redundants.STUDY_ID[df_redundants.CODE==icode]))>0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "650ba7bf",
   "metadata": {},
   "source": [
    "#### Cross check that the removal of redundant Patient IDs was successful:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ffa4c8",
   "metadata": {},
   "source": [
    "print(\"Number of Patient IDs which have been counted more than once:\", len([pid for pid in set(df_redundants.PATIENT_ID) if sum(df_clinical.PATIENT_ID==pid)>1]))\n",
    "print(\"Validation: Number of redundant samples in post-filtration :\",len([pid for pid in set(df_redundants.PATIENT_ID) if sum(df_clinical_NR.PATIENT_ID==pid)>1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6269a6eb",
   "metadata": {},
   "source": [
    "df_redundants.to_excel(os.path.join(cwd_interim,'Redundant_Patient_ID.xlsx'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d41a406",
   "metadata": {},
   "source": [
    "## Part 2: Count Mutations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0fd493e",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54feeef1",
   "metadata": {},
   "source": [
    "%%time\n",
    "# List All genes\n",
    "list_mutfile=[]\n",
    "iter1=0\n",
    "for istudyRaw in list_study_dirs:\n",
    "    os.chdir(os.path.join(cwd,istudyRaw))\n",
    "    # import the mutations extended file\n",
    "    df_mut_istudy=pd.read_csv('data_mutations_extended.txt',sep='\\t',dtype=str,comment='#',encoding='cp1252',quoting=3,keep_default_na=False)\n",
    "    keepcols=['Hugo_Symbol','Chromosome','Variant_Classification','Tumor_Sample_Barcode'] # Only these columns are needed\n",
    "    df_mut_istudy=df_mut_istudy[keepcols]\n",
    "    df_mut_istudy.dropna(subset=['Hugo_Symbol'],inplace=True,how='any')\n",
    "#     df_mut_istudy.replace(r'^\\s+$', np.nan, regex=True,inplace=True) # remove null rows. \n",
    "\n",
    "    # Limit the Variant_Classification included\n",
    "    var_list=['nonsense_mutation', 'frame_shift_del', 'frame_shift', 'frame_shift_ins', 'missense_mutation', 'missense', 'nonsense', 'in_frame_del',  'in_frame_ins','nonstop_mutation']\n",
    "    df_mut_istudy.Variant_Classification=df_mut_istudy.Variant_Classification.apply(lambda x:x.lower())\n",
    "    df_mut_istudy=df_mut_istudy[df_mut_istudy.Variant_Classification.isin(var_list)]\n",
    "    \n",
    "    # limit to clinically curated samples\n",
    "    df_clinical_istudy=df_clinical_NR[df_clinical_NR.STUDY_ID==istudyRaw]\n",
    "    df_mut_istudy=df_mut_istudy[df_mut_istudy.Tumor_Sample_Barcode.isin(df_clinical_istudy.SAMPLE_ID)]\n",
    "    \n",
    "    # Include only Unique genes within each sample\n",
    "    df_mut_istudy.drop_duplicates(subset=['Tumor_Sample_Barcode','Hugo_Symbol'],keep='first',inplace=True)\n",
    "\n",
    "    # Add ICD-code information to the mutation data\n",
    "    df_mut_istudy['CODE']=[df_clinical_istudy.CODE[df_clinical_istudy.SAMPLE_ID==sid].values[0] for sid in df_mut_istudy.Tumor_Sample_Barcode]\n",
    "    \n",
    "    # store mutations file in memory\n",
    "    df_mut_istudy['STUDY_ID']=istudyRaw\n",
    "    list_mutfile=list_mutfile+[df_mut_istudy]\n",
    "    \n",
    "    del df_mut_istudy\n",
    "    del df_clinical_istudy\n",
    "    \n",
    "    iter1+=1\n",
    "    clear_output()\n",
    "    print('Study Number ',iter1,' done:', istudyRaw)# track progress in case of errors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ef0a4ec",
   "metadata": {},
   "source": [
    "df_mutfiles=pd.concat(list_mutfile).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b4bd9fd",
   "metadata": {},
   "source": [
    "df_mutfiles.Hugo_Symbol=df_mutfiles.Hugo_Symbol.astype(str).apply(lambda x:x.upper())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecd7c28b",
   "metadata": {},
   "source": [
    "# List All genes\n",
    "geneset=list(set(df_mutfiles.Hugo_Symbol.values))\n",
    "remlist=[' ','Unknown',np.nan,'na','NA','NaN','NAN']\n",
    "for igene in remlist:\n",
    "    if igene in geneset:\n",
    "        geneset.remove(igene)\n",
    "geneset=sorted(geneset)\n",
    "print(len(geneset)) # Number of genes included in our study"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72e00300",
   "metadata": {},
   "source": [
    "# remove NaN values\n",
    "df_mutfiles.drop(df_mutfiles[[not(row) for row in df_mutfiles.Hugo_Symbol.isin(geneset)]].index,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b47e1aa7",
   "metadata": {},
   "source": [
    "df_mutfiles.to_csv(os.path.join(cwd_interim,'df_mutfiles.csv'),sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d5b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==BEGIN HERE== to skip re-importing raw genomic data.\n",
    "df_mutfiles=pd.read_csv(os.path.join(cwd_interim,'df_mutfiles.zip'),sep='\\t',dtype=str)\n",
    "geneset=list(set(df_mutfiles.Hugo_Symbol.values))\n",
    "histcodes=list(set(df_mutfiles.CODE.sort_values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900817c9",
   "metadata": {},
   "source": [
    "### Perform Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0c59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ae1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define Null Output Matrix: genes vs hist as Integer\n",
    "df_Out=pd.DataFrame(0,columns=['All']+histcodes,index=geneset+['Total'],dtype=int)\n",
    "# Construct the output matrix by iteratating over rows of reduced dataframe thereby covering each gene mutated for each sample\n",
    "def fun_Outdf(inpvec):\n",
    "    df_Out1=inpvec[1]\n",
    "    inpdf=inpvec[0]\n",
    "    for idx,row in inpdf.iterrows():\n",
    "        igene=row.Hugo_Symbol\n",
    "        icode=row.CODE\n",
    "        df_Out1.loc[igene,icode]=df_Out1.loc[igene,icode]+1\n",
    "        df_Out1.loc[igene,'All']=df_Out1.loc[igene,'All']+1\n",
    "    return df_Out1\n",
    "\n",
    "ncores=cpu_count()-2# number of cores the task can be split into\n",
    "imarkers=[i*int(len(df_mutfiles)/ncores) for i in range(ncores+1)]\n",
    "imarkers[-1]=len(df_mutfiles)\n",
    "datalist=[[df_mutfiles[imarkers[i]:imarkers[i+1]],df_Out[:].copy(deep=True)] for i in range(ncores)]\n",
    "if __name__ == '__main__': #I don't quite understand why this is necessary but it is a part of multiprocessing docs\n",
    "    po=Pool(ncores) # invoke 5 pooled threads/processes. \n",
    "    list_resdf=list(po.map(fun_Outdf,datalist)) \n",
    "    po.close() \n",
    "    po.join()\n",
    "\n",
    "for idf in list_resdf:\n",
    "    df_Out=df_Out+idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d376aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2544571, 2544571, 2544571)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check correct counts: All these numbers are same if all mutations were counted once\n",
    "df_Out.drop(columns='All').sum().sum(),df_Out['All'].sum(),len(df_mutfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0de25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an important point. We could choose to count the total number of samples however, then if the same sample showed up in two different studies, it will be counted as one. Instead, we consider the possibility that since some studies name samples simply by numbers, it is possible that two studies have similar name but different samples. So we count unique Study_ID+Sample_ID.\n",
    "# This is consistent since we already removed redundant Patient IDs with the same histology in a previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a11f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_mutfiles['StidSid']=[df_mutfiles.loc[idx,'STUDY_ID']+'_'+df_mutfiles.loc[idx,'Tumor_Sample_Barcode'] for idx in df_mutfiles.index]\n",
    "# Count number of cases 'Total' within each histology : Perform this action after filtering for curated and sequenced samples\n",
    "TotalRow=[setlen(df_mutfiles.StidSid.values)]+[setlen(df_mutfiles.StidSid[df_mutfiles.CODE==ihist].values) for ihist in df_Out.columns[1:]]\n",
    "df_Out.loc['Total']=TotalRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c2a3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ['n/a','NAN','NA','na','nan']:\n",
    "    if item in df_Out.index:\n",
    "        df_Out=df_Out.drop(index=item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7375be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Out=df_Out.drop(columns=df_Out.columns[df_Out.loc['Total']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e701f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test genomics pipeline pre-gene renaming, the interim file df_out can be output by un-commenting this command.\n",
    "df_Out.to_excel(os.path.join(cwd_interim,'df_Out_preGeneRename.xlsx'),index_label='Hugo_Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60747d0c",
   "metadata": {},
   "source": [
    "## PostProcessing: Remove redundant gene names and remove null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e5ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chDegen=pd.read_csv(os.path.join(cwd_interim,'Genelist_ManyChromosomes.xlsx'))# Only MARCH1 MARCH2 and SEPT15 have any real issues. This is very very likely due to excel errors someone made in the past by copying data incorrectly without realizing.\n",
    "degenchlist=df_chDegen[['Hugo_Symbol','Chromosome Locations','Entries_per_Location']].applymap(lambda x:str(x).upper()).values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c06dab2",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Identifying chromosomal degeneracies takes half an hour using 6 cores at >2Ghz. If not updating raw data, uncomment this step to skip next block.\n",
    "def fun_chromosome(inplist):\n",
    "    setlen=lambda x:len(set(x))\n",
    "    df_mutfiles=inplist[0]\n",
    "    geneset=inplist[1]\n",
    "    return [igene for igene in geneset if setlen(df_mutfiles[df_mutfiles.Hugo_Symbol==igene].Chromosome)>1]\n",
    "ncores=cpu_count()-2# number of cores the task can be split into\n",
    "imarkers=[i*int(len(geneset)/ncores) for i in range(ncores+1)]\n",
    "imarkers[-1]=len(geneset)\n",
    "gslist=[[df_mutfiles,geneset[imarkers[i]:imarkers[i+1]]] for i in range(ncores)]\n",
    "if __name__ == '__main__': #I don't quite understand why this is necessary but it is a part of multiprocessing docs\n",
    "    po=Pool(ncores) # invoke 6 pooled threads/processes. \n",
    "    list_degen=list(po.map(fun_chromosome,gslist)) \n",
    "    po.close() \n",
    "    po.join()\n",
    "degenchlist=[elem for row in list_degen for elem in row]\n",
    "degenchlist=[[igene,set(df_mutfiles[df_mutfiles.Hugo_Symbol==igene].Chromosome)] for igene in degenchlist]\n",
    "degenchlist=[[igene,ichlist,[sum(df_mutfiles[df_mutfiles.Hugo_Symbol==igene].Chromosome==ich) for ich in ichlist]] for igene,ichlist in degenchlist]\n",
    "# Check for chromosome assignment issues in the genomic dataset. > THey are present but minimal.\n",
    "df_chDegen=pd.DataFrame(degenchlist, columns=['Hugo_Symbol','Chromosome Locations','Entries_per_Location'])\n",
    "df_chDegen.to_csv(os.path.join(cwd_interim,'Genelist_ManyChromosomes.xlsx'))# Only MARCH1 MARCH2 and SEPT15 have any real issues. This is very very likely due to excel errors someone made in the past by copying data incorrectly without realizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03d2f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import alternate gene nomenclature file from cbioportal: https://docs.cbioportal.org/3.-cbioportal-maintenance/updating-gene-and-gene_alias-tables\n",
    "#Homo_sapien.gene_info.gz ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz\n",
    "dfGeneNames=pd.read_csv(os.path.join(cwd_refdata,'Homo_sapiens_gene_info_GM.txt'),sep='\\t',dtype=str)\n",
    "dfGeneNames=dfGeneNames.astype(str).applymap(lambda x:x.upper())\n",
    "dfGeneNames.Synonyms=[str(row).split('|') for row in dfGeneNames.Synonyms.values]\n",
    "listSynonyms=[elem for row in dfGeneNames.Synonyms.values for elem in row]\n",
    "def FindGeneName(igene):\n",
    "    retgene=np.nan\n",
    "    if (igene in set(dfGeneNames.Symbol)) or (igene not in set(listSynonyms)) or (igene in [row[0] for row in degenchlist]):\n",
    "        return igene\n",
    "    else:\n",
    "        retgene=dfGeneNames[[igene in row for row in dfGeneNames.Synonyms]].Symbol.values[0]\n",
    "    # proceed to rename if the chromosome no is same.    \n",
    "    chno_retgene=str(dfGeneNames[dfGeneNames.Symbol==retgene].chromosome.values[0])\n",
    "    chno_igene=str(df_mutfiles[df_mutfiles.Hugo_Symbol==igene].Chromosome.values[0])# to cover simple renaming situations\n",
    "    return retgene if ((chno_retgene==chno_igene) and (igene in geneset)) else igene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfC=df_Out[:].copy(deep=True)\n",
    "genesrenamed=[]\n",
    "genesadded=[]\n",
    "for igene in dfC.index:\n",
    "    newgene=FindGeneName(igene)\n",
    "    if (newgene != igene):\n",
    "        if (newgene in dfC.index.values):\n",
    "            dfC.loc[newgene]=dfC.loc[newgene].copy()+dfC.loc[igene].copy()\n",
    "            dfC.drop(igene,inplace=True)\n",
    "            genesadded=genesadded+[igene]\n",
    "        else:\n",
    "            dfC.loc[newgene]=dfC.loc[igene].copy()\n",
    "            dfC.drop(igene,inplace=True)\n",
    "            genesrenamed=genesrenamed+[igene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCadd=df_Out.loc[genesadded]\n",
    "dfCadd['Hugo_Symbol_parent']=[FindGeneName(igene) for igene in dfCadd.index]\n",
    "dfCadd=dfCadd[[dfCadd.columns[-1]]+list(dfCadd.columns[:-1])]\n",
    "dfCadd.to_excel(os.path.join(cwd_interim,'Genes_Added.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCren=df_Out.loc[genesrenamed]\n",
    "dfCren['Hugo_Symbol_new']=[FindGeneName(igene) for igene in dfCren.index]\n",
    "dfCren=dfCren[[dfCren.columns[-1]]+list(dfCren.columns[:-1])]\n",
    "dfCren.to_excel(os.path.join(cwd_interim,'Genes_Renamed.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360ad54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('len(genesrenamed),len(genesadded): ',len(genesrenamed),len(genesadded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1=list(dfC.index)\n",
    "idx1=sorted(idx1)\n",
    "idx1.remove('Total')\n",
    "idx1=idx1+['Total']\n",
    "dfC=dfC.loc[idx1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d198551",
   "metadata": {},
   "outputs": [],
   "source": [
    "colist=dfC.columns.sort_values()\n",
    "colist=[colist[-1]]+list(colist[:-1])\n",
    "dfC=dfC[colist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.to_csv(os.path.join(cwd0,'Genomics_Output_Processed.txt'),header=True,sep='\\t',index_label='Hugo_Symbol')\n",
    "print('Done. Results stored in Genomics_Output_Processed.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
